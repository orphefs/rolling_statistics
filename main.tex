% --------------------------------------------------------------
% This is all preamble stuff that you don't have to worry about.
% Head down to where it says "Start here"
% --------------------------------------------------------------
 
\documentclass[12pt]{article}
 
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb}
 
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
 
\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{reflection}[2][Reflection]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{proposition}[2][Proposition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
 
\begin{document}
 
% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------
 
%\renewcommand{\qedsymbol}{\filledbox}
 
\title{Rolling Mean and Variance of a Discrete Time Series}%replace X with the appropriate number
\author{Orfeas Kypris} %if necessary, replace with your course title
 
\maketitle
 
 
\begin{abstract}
    In this brief report, I am going to derive an expression for the rolling mean and variance of a discrete time series, which is useful for online applications, where limited computational resources don't allow the computation of the mean every time a new data point is received. This approach considers that the rolling mean and variance are computed with one incoming data point on every update, but can be extended to consider multiple data points at once.
\end{abstract}




\section{Windowed formulation for a window of duration $N-1$}

For a time window $[1,N]$, the mean and variance respectively become:


\begin{equation}
 \mu_{1:N} = \frac{1}{N} \sum^N_{i=1} x_i
 \label{mean}
\end{equation}

\begin{equation}
 \sigma^2_{1:N} = \frac{1}{N} \sum^N_{i=1} (x_i - \mu)^2
\label{std}
 \end{equation}

\section{Derivation of  Rolling Mean}

For the time window $[2,N+1]$, the mean becomes:

\begin{align}
 \mu_{2:N+1} &= \frac{1}{N} \sum^{N+1}_{i=2} x_i \\
	     &= \frac{1}{N} \sum^{N}_{i=1} \left( x_i + x_{N+1} - x_1 right) \\
	     &= \mu_{1:N} + \frac{1}{N} \left( x_{N+1} - x_1 \right)
 \label{mean}
\end{align}

Thus, we can express the windowed mean for a time window $[2,N+1]$, as a function of the mean for window $[1,N]$ and old data point $x_1$ and incoming data point $x_{N+1}$.


\section{Derivation of Rolling Variance}

For the time window $[1,N]$, the variance becomes:

\begin{align}
 \sigma_{1:N} &= \frac{1}{N} \sum^{N}_{i=1} \left( x_i - \mu_{1:N} \right)^2\\
	     &= \frac{1}{N} \sum^{N}_{i=1} \left( x_i^2  -2x_i \mu_{1:N} + \mu_{1:N}^2 \right)\\
	     &= \frac{1}{N} \sum^{N}_{i=1} x_i^2 - \mu_{1:N}^2 
 \label{mean}
\end{align}


Similarly, for the window $[2,N+1]$:

\begin{align}
 \sigma_{2:N+1} &= \frac{1}{N} \sum^{N+1}_{i=2} x_i^2 - \mu_{2:N+1}^2 
 \label{mean}
\end{align}
 
 Let $S=\sum_{i=1}^N x_i^2$. It follows that:
 
 \begin{equation}
     \sum_{i=2}^{N+1} x_i^2 = \sum_{i=1}^N x_i^2 - x_1^2 + x_{N+1}^2
 \end{equation}
 
 Thus, 
 
  
 \begin{align}
     \sigma^2_{2:N+1} &= \frac{1}{N} \sum_{i=2}^{N+1} x_i^2  - \mu^2_{2:N+1} \\
     &=  \frac{1}{N}  \sum_{i=1}^N \left( x_i^2 - x_1^2 + x_{N+1}^2 \right) - \mu^2_{2:N+1} \\
     &=  \frac{1}{N}  \sum_{i=1}^N \left( x_i^2 - x_1^2 + x_{N+1}^2 \right) - \mu^1_{1:N} + \left( -x_1^2 + x_{N+1}^2 \right)
 \end{align}
 
 Now we have an equation for the variance for the second time window $[2,N+1]$, with the precomputed terms from the first time window $[1,N]$, the old point $x_1$, the old mean $\mu_{1:N}$, and the new point $x_N$. This equation is useful if we want to compute the variance of a time series on-the-fly, without having to recompute the mean of the entire window every time we receive an incoming point.
 
 

 
% --------------------------------------------------------------
%     You don't have to mess with anything below this line.
% --------------------------------------------------------------
 
\end{document}